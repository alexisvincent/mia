// --------------- //
//    Tool types   //
// --------------- //



/**
 * Type of AI_ML_API's AI_ML_API_MODERATION_COMPLETION tool input.
 */
type AI_ML_API_MODERATION_COMPLETION_INPUT = {
  /**
   * Input
   * @description The content to classify for safety. For text, provide the raw string. For images, provide a URL or base64-encoded data URI.
   */
  input?: string;
  /**
   * Model
   * @description ID of the content moderation model to use. Choose any model from the documentation: https://docs.aimlapi.com/api-references/moderation-safety-models#all-available-content-moderation-models
   */
  model?: string;
};

/**
 * Type of AI_ML_API's AI_ML_API_MODERATION_COMPLETION tool output.
 */
type AI_ML_API_MODERATION_COMPLETION_OUTPUT = {
  /**
   * Data
   * @description Data from the action execution
   */
  data?: {
      /**
       * Raw
       * @description The raw classification output from the model. Typically 'safe' or 'unsafe', optionally with hazard categories.
       */
      raw: string;
  };
  /**
   * Error
   * @description Error if any occurred during the execution of the action
   * @default null
   */
  error: string | null;
  /**
   * Successful
   * @description Whether or not the action execution was successful or not
   */
  successful?: boolean;
};

/**
 * Type of AI_ML_API's AI_ML_API_TEXT_CHAT_COMPLETION tool input.
 */
type AI_ML_API_TEXT_CHAT_COMPLETION_INPUT = {
  /**
   * Frequency Penalty
   * @description Penalty for new tokens based on their existing frequency in the text.
   * @default 0
   */
  frequency_penalty: number | null;
  /**
   * Logit Bias
   * @description Adjust the likelihood of specified tokens appearing in the completion.
   * @default null
   */
  logit_bias: {
      [key: string]: number;
  } | null;
  /**
   * Max Tokens
   * @description Maximum number of tokens to generate in the response.
   * @default null
   */
  max_tokens: number | null;
  /**
   * Messages
   * @description List of message objects for conversation history.
   */
  messages?: {
      /**
       * Content
       * @description The content of the message.
       */
      content: string;
      /**
       * Role
       * @description The role of the message sender.
       * @enum {string}
       */
      role: "system" | "user" | "assistant";
  }[];
  /**
   * Model
   * @description The identifier of the model to use for generating responses.
   */
  model?: string;
  /**
   * N
   * @description Number of completions to generate for each prompt.
   * @default 1
   */
  n: number | null;
  /**
   * Presence Penalty
   * @description Penalty for new tokens based on whether they appear in the text so far.
   * @default 0
   */
  presence_penalty: number | null;
  /**
   * Stop
   * @description Up to four sequences where the API will stop generating further tokens.
   * @default null
   */
  stop: string[] | null;
  /**
   * Stream
   * @description Whether to stream the response as tokens are generated.
   * @default false
   */
  stream: boolean | null;
  /**
   * Temperature
   * @description Sampling temperature between 0 and 1; higher values make output more random.
   * @default 1
   */
  temperature: number | null;
  /**
   * Top P
   * @description Nucleus sampling threshold; model considers tokens with cumulative probability up to top_p.
   * @default 1
   */
  top_p: number | null;
  /**
   * User
   * @description Unique identifier representing the end-user.
   * @default null
   */
  user: string | null;
};

/**
 * Type of AI_ML_API's AI_ML_API_TEXT_CHAT_COMPLETION tool output.
 */
type AI_ML_API_TEXT_CHAT_COMPLETION_OUTPUT = {
  /**
   * Data
   * @description Data from the action execution
   */
  data?: {
      /**
       * Choices
       * @description List of completion choices.
       */
      choices: {
          /**
           * Finish Reason
           * @description Reason the model stopped generating tokens.
           * @default null
           */
          finish_reason: string | null;
          /**
           * Index
           * @description Index of this completion choice.
           */
          index: number;
          /**
           * Message
           * @description The message object generated by the model.
           */
          message: {
              /**
               * Content
               * @description The content of the message.
               */
              content: string;
              /**
               * Role
               * @description The role of the message sender.
               * @enum {string}
               */
              role: "system" | "user" | "assistant";
          };
      }[];
      /**
       * Created
       * @description Unix timestamp of when the completion was created.
       */
      created: number;
      /**
       * Id
       * @description Unique identifier for the completion.
       */
      id: string;
      /**
       * Model
       * @description The model used for the completion.
       */
      model: string;
      /**
       * Object
       * @description Type of object returned, e.g., 'chat.completion'.
       */
      object: string;
      /**
       * Usage
       * @description Token usage statistics for the request.
       */
      usage: {
          /**
           * Completion Tokens
           * @description Number of tokens in the generated completion.
           */
          completion_tokens: number;
          /**
           * Prompt Tokens
           * @description Number of tokens in the input prompt.
           */
          prompt_tokens: number;
          /**
           * Total Tokens
           * @description Total number of tokens used (prompt + completion).
           */
          total_tokens: number;
      };
  };
  /**
   * Error
   * @description Error if any occurred during the execution of the action
   * @default null
   */
  error: string | null;
  /**
   * Successful
   * @description Whether or not the action execution was successful or not
   */
  successful?: boolean;
};

/**
 * Type map of all available tool input types for toolkit "AI_ML_API".
 */
export type AI_ML_API_TOOL_INPUTS = {
  MODERATION_COMPLETION: AI_ML_API_MODERATION_COMPLETION_INPUT
  TEXT_CHAT_COMPLETION: AI_ML_API_TEXT_CHAT_COMPLETION_INPUT
}

/**
 * Type map of all available tool input types for toolkit "AI_ML_API".
 */
export type AI_ML_API_TOOL_OUTPUTS = {
  MODERATION_COMPLETION: AI_ML_API_MODERATION_COMPLETION_OUTPUT
  TEXT_CHAT_COMPLETION: AI_ML_API_TEXT_CHAT_COMPLETION_OUTPUT
}

// ------------------- //
//    Trigger types    //
// ------------------- //



/**
 * Map of Composio's AI_ML_API toolkit.
 */
export const AI_ML_API = {
  slug: "ai_ml_api",
  tools: {
    /**
     * Tool to classify input text or image for safety using a moderation model. use after receiving user-generated content to filter out unsafe material.
     */
    MODERATION_COMPLETION: "AI_ML_API_MODERATION_COMPLETION",
    /**
     * Tool to generate text completions or chat responses using a specified llm model. use after assembling the conversation history to produce the next response.
     */
    TEXT_CHAT_COMPLETION: "AI_ML_API_TEXT_CHAT_COMPLETION",
  },
  triggerTypes: {},
}

/**
 * Type map of all available trigger payloads for toolkit "AI_ML_API".
 */
export type AI_ML_API_TRIGGER_PAYLOADS = {}

/**
 * Type map of all available trigger events for toolkit "AI_ML_API".
 */
export type AI_ML_API_TRIGGER_EVENTS = {}
